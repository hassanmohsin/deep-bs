{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from data.base_dataset import *\n",
    "from data.pdbbind_dataset import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nc = 24\n",
    "bs = 16\n",
    "\n",
    "tfms = transforms.Compose([Center(),\n",
    "                           Rotate(90),\n",
    "                           Channel(['C'], input_nc, 1.0, 1.4),\n",
    "                           Channel(['O'], input_nc, 1.0, 1.4),\n",
    "                           Channel(['N'], input_nc, 1.0, 1.4),\n",
    "                           ToTensor()])\n",
    "class Option:\n",
    "    csvfile = path/'refined_set.csv'\n",
    "    dataroot = '../../../2018/refined-set/'\n",
    "    channels = 'cno'\n",
    "    grid_size = 20\n",
    "    grid_spacing = 1\n",
    "    rvdw = 1.4\n",
    "    filter_kd = True\n",
    "    rotate = 10\n",
    "\n",
    "opt = Option()\n",
    "ds = PdbBindDataset()\n",
    "ds.initialize(opt)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=bs,\n",
    "                                 shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.32587341e-15,   9.32587341e-15,   9.32587341e-15,\n",
       "          9.32587341e-15,   9.32587341e-15,   9.32587341e-15,\n",
       "          9.32587341e-15,   9.32587341e-15,   9.32587341e-15,\n",
       "          9.32587341e-15,   9.32587341e-15,   9.32587341e-15,\n",
       "          9.32587341e-15,   9.32587341e-15,   9.32587341e-15,\n",
       "          9.32587341e-15,   9.32587341e-15,   9.32587341e-15,\n",
       "          9.32587341e-15,   9.32587341e-15,   9.32587341e-15],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data['grids'][0,0].cpu().numpy(), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv3d(6, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv3d(16, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv3d(16, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (5): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (6): Fire(\n",
       "      (squeeze): Conv3d(128, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv3d(32, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv3d(32, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (8): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv3d(256, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv3d(48, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv3d(384, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv3d(48, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (11): Fire(\n",
       "      (squeeze): Conv3d(384, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv3d(64, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv3d(512, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (squeeze_activation): ReLU(inplace)\n",
       "      (expand1x1): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace)\n",
       "      (expand3x3): Conv3d(64, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Flatten()\n",
       "    (1): Dropout(p=0.5)\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SqueezeNet(input_nc=6)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 42.319\n",
      "[1,    40] loss: 45.145\n",
      "[1,    60] loss: 45.195\n",
      "[1,    80] loss: 38.745\n",
      "[1,   100] loss: 42.507\n",
      "[1,   120] loss: 42.891\n",
      "[2,    20] loss: 45.096\n",
      "[2,    40] loss: 40.623\n",
      "[2,    60] loss: 42.159\n",
      "[2,    80] loss: 40.413\n",
      "[2,   100] loss: 43.612\n",
      "[2,   120] loss: 46.234\n",
      "[3,    20] loss: 45.709\n",
      "[3,    40] loss: 38.737\n",
      "[3,    60] loss: 41.660\n",
      "[3,    80] loss: 49.065\n",
      "[3,   100] loss: 39.815\n",
      "[3,   120] loss: 45.227\n",
      "[4,    20] loss: 43.844\n",
      "[4,    40] loss: 43.751\n",
      "[4,    60] loss: 45.393\n",
      "[4,    80] loss: 42.424\n",
      "[4,   100] loss: 43.655\n",
      "[4,   120] loss: 39.146\n",
      "[5,    20] loss: 40.133\n",
      "[5,    40] loss: 43.738\n",
      "[5,    60] loss: 46.688\n",
      "[5,    80] loss: 44.534\n",
      "[5,   100] loss: 42.289\n",
      "[5,   120] loss: 40.027\n",
      "[6,    20] loss: 42.493\n",
      "[6,    40] loss: 45.166\n",
      "[6,    60] loss: 42.097\n",
      "[6,    80] loss: 43.195\n",
      "[6,   100] loss: 41.787\n",
      "[6,   120] loss: 47.753\n",
      "[7,    20] loss: 46.517\n",
      "[7,    40] loss: 41.264\n",
      "[7,    60] loss: 39.224\n",
      "[7,    80] loss: 44.188\n",
      "[7,   100] loss: 45.179\n",
      "[7,   120] loss: 41.914\n",
      "[8,    20] loss: 42.662\n",
      "[8,    40] loss: 45.317\n",
      "[8,    60] loss: 40.997\n",
      "[8,    80] loss: 40.659\n",
      "[8,   100] loss: 44.622\n",
      "[8,   120] loss: 46.441\n",
      "[9,    20] loss: 44.803\n",
      "[9,    40] loss: 46.999\n",
      "[9,    60] loss: 39.653\n",
      "[9,    80] loss: 44.818\n",
      "[9,   100] loss: 41.919\n",
      "[9,   120] loss: 43.537\n",
      "[10,    20] loss: 39.665\n",
      "[10,    40] loss: 43.303\n",
      "[10,    60] loss: 44.417\n",
      "[10,    80] loss: 43.460\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(dl, 0):\n",
    "        grids = data['grids'].to(device)\n",
    "        affinities = data['affinity'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(grids)\n",
    "        loss = criterion(outputs, affinities)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.8296],\n",
       "        [10.4283],\n",
       "        [ 9.4874],\n",
       "        [ 9.2714],\n",
       "        [ 9.8149]], device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.5685],\n",
       "        [ 4.7105],\n",
       "        [ 2.8134],\n",
       "        [ 5.8091],\n",
       "        [16.1181]], device='cuda:1')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
